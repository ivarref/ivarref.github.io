---
draft: true
title: Databasek√∏ar, batching og 1400 GB XML
---

## Bakgrunn

Eg hadde sagt ja til √• forbetra hastigheita p√• eit legacysystem. Kor vanskeleg kunne det vera?

Eg hadde f√•tt det for meg at det var
snakk om rundt 70 GB XML det skulle prosessera. Det viste seg √• vera
1400 GB XML. Kjeldekoden var skriven i Python 2 (end of life i 2020), hadde ingen testar,
ingen spesifiserte avhengigheiter og innehaldt i tillegg rundt ti tusen linjer
med SQL, prim√¶rt i form av prosedyrer.

Koden, som skulle gjera ein import av XML-en,
hadde ei k√∏yretid p√• fleire m√•nadar.

Sluttresultatet skulle vera ein PostgreSQL
database med rundt 80 tabellar. Det var med andre ord det ein kunne kalla _interessant_ prosjekt.

## Kviss

Kor lang tid tek det √• utf√∏ra `SELECT version()` fr√• ein backend til ein PostgreSQL-instans?

Tenk p√• det. Tenk p√• det litt til.

Og √∏rlite til ja ‚Ä¶

Okei. Det f√•r duge. Takk.

## Svar kviss

Svaret er: det kjem an p√•.

For det fyrste kan det oppst√• nettverksfeil.
Er ein maks uheldeg
kan backenden ha motteke ein TCP acknowledgement og deretter at tilkoblinga vert droppa utan at backenden
f√•r beskjed. D√• endar ein opp med
[√• venta i all evigheit](https://blog.cloudflare.com/when-tcp-sockets-refuse-to-die/).

Ein anna nettverksfeilcase er at tilkoblinga vert droppa f√∏r TCP ACK er kome.
D√• f√•r ein ein
[timeout p√• omlag 924.6 sekund](https://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt).

Dersom k√∏yrer docker swarm, kan
[tilkoblinga fryse etter 15 minutt](https://github.com/moby/moby/issues/37466#issuecomment-405537713).

Desse problema kan ein handsama ved √• setja socket timeout (jdbc, psycopg) og/eller keep alive.
Eg har snakka om dette [her](https://www.youtube.com/watch?v=jQi_D4cosr0).

La oss anta at det ikkje er noko nettverksfeil:

```
PostgreSQL k√∏yrande lokalt:  40 microsekund (1x) (mi maskin, MacBook Air M3)
Azure Container App:        160 microsekund (4x)
lima-vm/docker for mac:     200 microsekund (5x)

=> RTT: Round Trip Time. Gjennomsnitt av 100 000 m√•lingar.
```

Ein ser med andre ord at eit produksjonsoppsett kan vera fire gonger treigare enn
lokalt oppsett, prim√¶rt grunna nettverket.

Om ein ynskjer eit lokalt oppsett _med nettverkstreigheit_, kan ein f.eks. nytta
[traffic control](https://jvns.ca/blog/2017/04/01/slow-down-your-internet-with-tc/) (linux)
eller 
[packet filter & traffic shaper](https://serverfault.com/questions/725030/traffic-shaping-on-osx-10-10-with-pfctl-and-dnctl)
(mac).


## UPSERTs: atomisk innleggjelse eller oppdatering av tabellverdiar

La oss anta at ein har fylgjande tabell:

```sql
CREATE TABLE s.shopping_list(item_name TEXT PRIMARY KEY,
                             cnt       BIGINT NOT NULL); 
                             -- cnt = count = antall ein skal kj√∏pa
```

I f√∏rre avsnitt s√•g ein at nettverksrundetida, round trip time (RTT), er sentralt
for kor raskt ei sp√∏rring g√•r. Det vanleg √• skilja mellom `UPDATEs`
og `INSERTs` p√• backend-sida. Ein kan ofte sj√• fylgjande kode:

```python
existing_cnt = SELECT cnt from s.shopping_list WHERE item_name = ...
if existing_cnt:
    UPDATE s.shopping_list SET cnt = ? WHERE item_name = ?
else:
    INSERT INTO s.shopping (item_name, cnt) VALUES (?, ?)
```

Dette ovanfor krever to nettverksrundar. Det finst ein raskare m√•te:

`UPSERTs`, som tyder `INSERT` or `UPDATE`, er st√∏tta av ulike databasar.
For PostgreSQL ser eksempelet over slik ut:

```sql
INSERT INTO s.shopping_list (item_name, cnt) VALUES (?, ?)
ON CONFLICT (item_name) DO UPDATE SET
cnt = s.shopping_list.cnt + EXCLUDED.cnt;

-- dersom ein ikkje vil gjera UPDATE og unng√• Unique Violation Constraint:
-- ON CONFLICT (item_name) DO NOTHING
```

`EXCLUDED.<kolonnenamn>` tyder det ein sender inn som input.
`s.shopping_list.cnt` referer til det som allereie ligg i databasen.
Det ein gjer her er √• leggja inn eller plussa p√• eksisterande verdi
for ei gitt rad i √©in nettverksrunde.

## Batching: raskare innleggjelse i databasen

I Python kan ein skriva fylgjande kode:

```python
cursor = conn.cursor()
sql = 'INSERT INTO s.shopping_list (item_name, cnt) VALUES (%s, %s)'
      # Kan ogs√• ha ON CONFLICT (item_name) ... 

cursor.execute(sql, ('Filterkaffi', 1))
cursor.execute(sql, ('H-mj√∏lk', 4)) # Treng mykje mj√∏lk til √• laga graut
                                    # og ikkje minst til √• ha i kaffien
```

Kvar `cursor.execute` gjer ein full nettverksrunde (round trip time), og dette tek un√∏dvendig
mykje tid. Batchversjonen i Python ser slik ut:

```python
cursor.executemany(sql, [('Filterkaffi', 1), ('H-mj√∏lk', 4)])
```

Tilsvarande kode i vanleg Java
kan nytta
[java.sql.PreparedStatement](https://docs.oracle.com/en/java/javase/21/docs/api/java.sql/java/sql/PreparedStatement.html):

```java
String sql = "INSERT INTO s.shopping_list (item_name, cnt) VALUES (?, ?)";
PreparedStatement pstmt = conn.prepareStatement(sql);

pstmt.setString(1, "Filterkaffi");
pstmt.setInt(2, 1);
pstmt.addBatch();

pstmt.setString(1, "H-mj√∏lk");
pstmt.setInt(2, 4); // 4 x h-mj√∏lk til grauten
pstmt.addBatch();

pstmt.executeUpdate();
```

Med batching unng√•r ein full nettverksrunde for kvar rad. Ein sender i staden
kvar `INSERT` samla i ein batch.

Eit `prepared statement` tyder at databaseserveren parser og planlegg queryet
og tek vare p√• resultatet i serversesjonen. I [psycopg](https://psycopg.org),
Python sin PostgreSQL drivar,
vert det automatisk gjort `prepared statements` dersom eit query har
[k√∏yrd fleire enn 5 gonger](https://www.psycopg.org/psycopg3/docs/advanced/prepare.html).
Det same gjeld den
[PostgreSQL JDBC drivaren](https://jdbc.postgresql.org/documentation/server-prepare/#server-prepared-statements)
for Java.

## PostgreSQL: COPY protokollen

PostgreSQL har, i tillegg til prepared statements, ein eigen
[copy protokoll](https://www.postgresql.org/docs/current/sql-copy.html).
Den er enno raskare enn en batching.
`psycopg` st√∏ttar denne protokollen, og bruken av det ser slik ut:

```python
copy_sql = 'COPY s.shopping_list (item_name, cnt) FROM STDIN'
with cursor.copy(copy_sql) as copy:
  copy.write_row(('Filterkaffi', 1))
  copy.write_row(('H-mj√∏lk', 4)) # Ein lyt ha mj√∏lk. Elles vert det kaffimage
```

Ei ulempe med COPY-protokollen er at den ikkje st√∏ttar konflikthandsaming.
Det vil seia at den ikkje har noko konsept tilsvarande `UPSERTs`. Dersom
ein legg inn ein duplikat i COPY-protokollen, vil transaksjonen feila.

## Ytelsestest i Azure

`INSERTs` med 100 sekvensielle transaksjonar √† 1000 rader, totalt 100 000 rader:

```
COPY:     10 micros/rad (1x)
Batch:    60 micros/rad (6x)
Single:  180 micros/rad (18x)
```

I denne testen var single `INSERTs` 18 gonger treigare enn `COPY` og
3 gonger treigare enn med batching. Merk at ein her nytta ein 100 sekvensielle
transaksjonar. Dette tyder at ein batch fekk ei √∏vre grense p√• 1 000 items
som s√• vart skrive til databasen og ein laut venta p√• ein nettverksrunde.
Dermed vil den relative vinsten med batching auka
saman med antall p√• items i ein batch.

## IO vs CPU

P√• dette stadiet i prosjektet hadde eg kun utvikla lokalt p√• mi b√¶rbare datamaskin,
ein MacBook Air M3.
Programmet hadde vorte ganske mykje raskare enn det var opprinneleg.

![Dell PowerEdge R6525 vs MacBook Air M3 2024](/images/dell_vs_macair.png)

Det var no p√• tide √• k√∏yra det p√• produksjonsserveren: ein Dell PowerEdge R6525 server
med 32 kjernar, 2 TB RAM og eit par NVMe diskar som kosta over hundre tusen per stykk.
"Dette er ikkje ein vanleg d√∏deleg server," som ein kollega uttrykte det.

Og kvar k√∏yrde programmet raskast? Jod√•, p√• min lokale b√¶rbar. Eg fekk till√∏p til panikk.

Ein kunne ikkje skulda p√• nettverket: p√• serveren k√∏yrde PostgreSQL databasen lokalt.

Eg samanlikna diskytelsen p√• serveren med bruk av kommandoar som
`dd if=/dev/zero of=out1 bs=1024k count=1000 oflag=direct`
og `ioping`.
Lesing var raskare p√• mi maskin, medan skriving var raskare p√• serveren.

Etter √• ha kikka p√• ytelsen med [pgtop](https://pg_top.gitlab.io/), vart det etterkvart
kl√•rt at dette var ei CPU-bound oppg√•ve. Ein kan √≤g nytta verkt√∏y som `mpstat -P ALL`.
D√• s√•g ein at `iowait`, dvs. venting p√• disk, var l√•gt, medan CPU-bruk var h√∏gt.
Slike verkt√∏y og analysemetodar er godt skildra i boka
[Systems performance: Enterprise and the Cloud](https://www.brendangregg.com/systems-performance-2nd-edition-book.html)
av Brendan Gregg.

Ei endeleg stadfesting fekk eg d√• eg k√∏yrde det p√• min gamle linuxb√¶rbar.
B√•de disklesing og -skriving var treigare der enn p√• serveren,
likevel gjekk det raskare enn p√• den gamle b√¶rbaren. Og vifta gjekk i taket.
CPU-en p√• min gamle linuxb√¶rbar var kraftigare enn den litt eldre "superserveren"
med 2 TB RAM.

MacBook Air (M*) er som kjent viftelaus, s√• eg hadde rett og slett ikkje tenkt
mykje p√• CPU-bruk, s√¶rleg ettersom bruken skjedde p√• ein-to av √•tte tilgjengelege kjernar.

Uansett hadde det vore kl√•rt fr√• byrjinga at ein burde paralellisera arbeidet:
Det er greit √• nytta dei CPU-ane ein faktisk har.

## Parallelliseringskviss

Kor lang tid tek det √• utf√∏ra fylgjande transaksjon?

```sql
UPDATE s.shopping_list SET cnt = cnt*2 WHERE item_name = 'Filterkaffi'
UPDATE s.shopping_list SET cnt = cnt*2 WHERE item_name = 'H-mj√∏lk'

```

Tenk p√• det. Ikkje altfor for hardt, ikkje altfor lett, men s√•nn passe.

Var det ein lurekviss? Tja. Svaret er uansett som p√• f√∏rre kviss:
det kjem an p√•. Denne gongen skal det handla
om kva anna som skjer samstundes i databasen.

La oss seia at annan transaksjon held ein l√•s p√• rada med "H-mj√∏lk".
D√• lyt ein n√∏dvendigvis venta til den har committa f√∏r ein f√•r gjort noko.
Men kva om s√• den andre transaksjonen ynskjer √• skriva til rada med "Filterkaffi",
den rada som denne transaksjonen held ein l√•s p√•,
f√∏r den committer? D√• f√•r ein ein deadlock. Dette er meir utfyllande forklart i
[denne artikkelen](https://www.cybertec-postgresql.com/en/postgresql-understanding-deadlocks/).

Poenget er forhaldsvis enkelt:
det er ikkje n√∏dvendigvis uproblematisk √• skriva batchar av data til same tabell fr√•
fleire prosessar samstundes. Blant anna deadlocks og lange ventetider kan oppst√•.
Kan parallelliseringa gjerast enklare, dvs. utan √• m√•tta tenkja p√• rekkefylgje
og l√•sing?

## Parallelliseringsstrategi

Som eg skreiv i byrjinga s√• var det rundt 80 tabellar i dette systemet.
Ein XML "item" skulle enda opp i 80 ulike tabellar.

Ein naiv parallelliseringsstrategi ville sj√• slik ut:
```
Process 1: item-1 => tbl_1, tbl_2 ‚Ä¶ tbl_80
Process 2: item-2 => tbl_1, tbl_2 ‚Ä¶ tbl_80
Process 3: item-3 => tbl_1, tbl_2 ‚Ä¶ tbl_80
```

Dette ovanfor, som eg argumenterte for tidlegare, vil lett kunne skapa deadlocks
og lange ventetider. I staden er det betre √• laga eit k√∏system.
√âin k√∏ (transaksjon) skriv til √©in tabell. Ingen av k√∏ane skriv til dei same tabellane.
Slik ser ei enkel skisse ut:

```
K√∏system
Process/k√∏ 1: item-1, item-2, item-3 => tbl_1 + => k√∏_2
Process/k√∏ 2: item-1, item-2, item-3 => tbl_2 + => k√∏_3
Process/k√∏ 3: item-1, item-2, item-3 => tbl_2 + => k√∏_4
```

Tanken her er at ein k√∏ i tillegg til √• skriva til ein tabell,
√≤g sender XML-itemet vidare til neste k√∏.
Her er det, som du vonleg ser, gode moglegheiter for batching.

Litt forenkla kan ein seia at total k√∏yretid for systemet
vert:

`treigaste k√∏ * antall items`

Korleis lagar ein eit slikt k√∏system?

## Concurrent batchk√∏

Ein ynskjer fylgjande eigenskapar til k√∏systemet:

* Transaksjonell og del av same database.
* Fleire consumers, ogs√• for same k√∏.
* Feilhandsaming: rollback og eventuelt retry.
* Minst mogleg styr.

Med "minst mogleg styr", mitt favorittpunkt,
meinar eg at ein b√∏r unng√•
ting som `compare-and-swap`, venting p√• l√•sar & deadlocks, uturvande koordinering
mellom prosessar og liknande.

SQL har desse eigenskapane i form av `FOR UPDATE SKIP LOCKED` og `SAVEPOINT`.

I tillegg treng ein √≤g ein enkel tabell for √• halda styr p√• k√∏-items.
Eksempelvis:

```sql
CREATE TABLE batch_queue(id         PRIMARY KEY,
                         queue_name TEXT NOT NULL,
                         status     TEXT NOT NULL, 
                         payload    TEXT NOT NULL)
```
## SELECT ‚Ä¶ FOR UPDATE SKIP LOCKED

`SELECT ‚Ä¶ FOR UPDATE SKIP LOCKED` er som orda tilseier:

* Ein selecter rader (`SELECT ‚Ä¶`).
* Seier i fr√• til databasen at desse kjem til √• verta oppdatert (`FOR UPDATE`).
  Dette tyder at ein l√•ser radene.
* Ignorerer allereie l√•ste rader.

Dette vert gjort i √©in operasjon. Det er d√• ikkje nokon sjanse for at det vert
l√•sekonflikt eller -venting mellom ulike transaksjonar.

## SAVEPOINTs

La oss seie fylgjande psuedokode k√∏yrer:

```
Hent k√∏jobb: SELECT * FROM batch_queue FOR UPDATE SKIP LOCKED ...
K√∏jobb: INSERT INTO tbl_1 => OK
        INSERT INTO tbl_2 => üí•UniqueConstraintViolationüí•
        => Rulle attende alt?
```

Skal ein d√• rulle attende alt? D√• mistar ein l√•sen for batchk√∏-radene. Ein annan
consumer kan d√• ta radene og f√• same feil p√• nytt. Skal ein committe?
D√• f√•r ein ein delvis utf√∏rt k√∏jobb. Ein ynskjer ingen av delene.

Det er her [SAVEPOINT](https://www.postgresql.org/docs/current/sql-savepoint.html)s kjem
inn i biletet. Det er √≤g kjent under namna `nested transactions` og `subtranction`.

> A savepoint is a special mark _inside a transaction_ that allows all commands that are executed
> after it was established to be rolled back,
> restoring the transaction state to what it was at the time of the savepoint.

Sitat fr√• PostgreSQL-dokumentasjonen og med mi utheving:
med `SAVEPOINTs` kan ein rulla attende _ein del_ av ein transaksjonen.

## Concurrent batchk√∏

Psuedokode for ein concurrent batchk√∏ med `SAVEPOINTs` kan sj√• slik ut:

```
SELECT * FROM batch_queue WHERE status='INIT' FOR UPDATE SKIP LOCKED ...
SAVEPOINT pre_queue_consumer_fn
try:
  k√∏jobb funksjon: INSERT INTO tbl_1 OK
  k√∏jobb funksjon: INSERT INTO tbl_2 üí•UniqueConstraintViolationüí•
  UPDATE batch_queue status=‚ÄôDONE‚Äô WHERE ...
except Exception:
  ROLLBACK TO pre_queue_consumer_fn 
  UPDATE batch_queue SET status=‚ÄôERROR‚Äô WHERE ‚Ä¶
COMMIT
```

Her nyttar ein `SAVEPOINTs` for √• kunne gjera to ting: rulla attende det som har skjett
inne i k√∏jobbfunksjonen _samstundes_ som ein framleis held p√• dei l√•ste radene i batchk√∏tabellen.
Dette gjev oss dei eigenskapane me ynsker oss:

* Ein kan ha fleire consumers per k√∏ om ein ynskjer det. Consumers vil ikkje g√• i beina p√•
kvarandre, √≤g om ein skulle rulla attende.

* Ein f√•r rulla attende n√∏yaktig det ein ynskjer, samstundes som ein ikkje slepp batchk√∏l√•sen.
  Det b√∏r vera grei skuring √• i tillegg leggja til retry. Om ein har henta ut ti k√∏items,
  kan ein f.eks. pr√∏va ein og ein p√• nytt i separate transaksjonar.

* "Minst mogleg styr." Databasen gjer all koordineringa for oss. Konsumentar kan k√∏yra p√•
  heilt separate prosessar eller maskiner. Det er godt √• ikkje trenga √• bekymra seg over eigne
  moglegheiter for race conditions og liknande.

## Resultat

Prosjektet kom etterkvart i m√•l. Det vart rundt 30 k√∏ar og 80 k√∏konsumentar.
Det vart ingen inter process communication eller moglegheiter for race conditions.
Koden er framleis mogleg √• resonnera om.

Hovudm√•let for prosjektet vart n√•dd: k√∏yretida gjekk fr√• manadar til √©in dag!

Med det er det berre √• avslutta med [Olav H](https://www.nrk.no/kultur/_det-er-den-draumen_-er-norges-beste-dikt-1.13140034):

_Det er den draumen me alle ‚Äì eller i det minste sume av oss ‚Äì ber p√•:\
at noko vedunderleg skal skje\
at vekes- og sletteimporten skal k√∏yra f√∏r jol\
at det m√• skje\
at mogleg fr√•v√¶r av indeksar ikkje skal skapa problem\
at sn√∏ggleiken ikkje g√•r dramatisk ned ved oppdatering\
at tidi per importeining held seg konstant\
at me ei morgonstund skal dukka ned\
i data me ikkje har visst um_

***

‚ù§Ô∏è Takk til alle som bidrog! ‚ù§Ô∏è

[//]: # (_Takk til ... for innspel, kommentarar og hjelp._)